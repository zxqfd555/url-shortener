# Постановка задачи

Необходимо разработать сокращалку URL-ов (как t.co или goo.gl). Должны быть поддержаны следующие функции:

  - Добавить ссылку. Для нее необходимо вернуть сокращенный URL, то есть URL вида "sh.co/shrt". Для ссылки задается время, которое она живет на сервере с момента последнего доступа.
  - Проследовать по сокращенной ссылке. Необходимо перенаправить пользователя по актуальному URL-у, либо вернуть 404 если ссылки нет, либо она была удалена вследствие протухания.

# API

Два endpoint-а.

Подход: недо-REST. От REST мы возьмем глаголы в методе запроса, statelessness. HATEOAS как "карту" методов API реализовывать не будем, так как оно достаточно простое.

## Добавить сокращенную ссылку

POST `/link`
Тело запроса - JSON с полями:
  - `"url"` -- адрес ссылки;
  - `"timeout"` -- гарантированное время жизни ссылки после добавления или последнего доступа к ней (whatever happens last) в секундах.

Варианты ответа:
  - Успех. Код 201, в заголовке `Location` - сокращенный URL, вместе с хостом (то есть, например: "sh.co/shrt").
  - Плохой формат запроса. Код 400. Если в JSON-е в теле нет поля `"url"` или `"timeout"`.

## Проследовать по сокращенной ссылке

GET `/<slug>`

Варианты ответа:

  - Успех. Код 301, в заголовке `Location` - реальный URL. То есть, перенаправление по актуальному URL-у.
  - Такой ссылки нет. Код 404. Это могло случиться по двум причинам: по этой ссылке никогда ничего и не было или же истек дедлайн с времени последнего доступа.

# CAP и архитектура

Будем целиться в CP-гарантии. Мотивация: когда пользователь сокращает ссылку, он зачастую сразу хочет поделиться ей с кем-то. Поэтому важно, чтобы по сокращенной ссылке доступ был сразу же.

С другой стороны, мы не будем пытаться добиться того, чтобы ссылка исчезала в точности после выставленного дедлайна. Мы разрешим ссылке жить еще недолго после протухания, давая гарантию лишь на то, что если не было окна длиной в TTL, в котором обращений по ссылке не было, то ссылка всегда будет не в удаленном состоянии. Если такое окно уже прошло, а ссылку мы удалить не успели, и по ней походили, то мы все также будем стараться ее продлить, однако 100%-гарантий уже не дается. Позже покажем, что наше решение имеет модель консистентности eventual consistency.

Дальше рассмотрим два решения, из которых возьмем второе.
В качестве БД для хранения основных данных возьмем MongoDB, настроенную на CP-гарантии с использованием механизма консенсусов.

В MongoDB одна коллекция - описание сокращенных ссылок. Документы в этой коллекции - отображения из slug (короткого URL) в следующие поля:

  - **expiration_timestamp**. Целое число, UTC timestamp того момента, когда ссылка начнет считаться протухшей. По этому полю имеем индекс для быстрого выбора всех записей в каком-то полуинтервале. Может меняться.
  - **ttl**. Сколько в секундах ссылка должна гарантированно жить после последнего обращения.
  - **url**. URL того ресурса, на который ссылка должна вести.
  
## Первое решение

Каждый раз, когда приходит запрос на запись - генерируем slug. Генерируем случайным образом, взяв шесть случайных символов из множества маленьких, больших английских букв и цифр. Получаем 26+26+10 = 62 варианта символа на каждой позиции или 56,800,235,584 вариантов ссылок. Будем действовать следующим образом: сгенерируем slug, если такой в базе есть, то будем повторять, пока не найдем такой, которого в базе нет. Как только валидный slug есть - просто пишем в нашу коллекцию новый маппинг: 
  slug -> {
    expiration_timestamp: текущий timestamp + ttl,
    ttl: заданный нам TTL ссылки в секундах,
    url: URL ресурса, на который должна вести ссылка
  }

Каждый раз, когда приходит запрос - достаем ссылку по slug-у и если она протухла (expiration_timestamp < текущий timestamp), то отдаем 404. Иначе - отдаем результат и меняем по ключу slug-а значение expiration_timestamp на (текущий timestamp) + ttl.

Регулярным фоновым процессом удаляем и все остальные просроченные ссылки, выбирая те, у которых expiration_timestamp < (текущий timestamp).

## Второе решение

Первое решение плохо тем, что на каждую операцию получения ссылки у нас идет запись в БД, которая более тяжелая, чем чтение.

Для того, чтобы этого избежать, предлагается завести регулярный процесс, который будет действовать следующим образом: раз в 5 минут со всех инстансов собираются логи (например, логи nginx). В сложной распределенной системе логи могут доезжать в распределенное хранилище, например. Затем, по этим логам, например, с помощью MapReducе можно построить для slug-ов которые за последние пять минут встретились отображение во времена последнего использования. Затем, согласно этим временам можно в базе продлить время жизни этим объектам.

Тогда добавление ссылки никак не меняется по сравнению с предыдущим решением. Переход по ссылке будет обрататываться следующим образом:

  - Достаем из MongoDB для slug-a структуру с информацией о ссылке. Если такой нет - 404. Если ссылка уже протухла - 404.
  - Если ссылке осталось жить меньше, чем (регулярность процесса по обработке логов) + (время работы процесса по обработке логов), то продлеваем ее время жизни прямой записью в MongoDB и редиректим по оригинальному URL-у.
  - Если ссылке осталось жить больше, чем обозначенное выше время, то о продлении срока жизни волноваться не стоит - это сделает регулярный процесс на следующей своей итерации. Просто редиректим по оригинальному URL-у.
  
Таким образом получается сократить число DB write-ов, особенно, если TTL-ы в среднем не очень маленькие (дни).

Если предположить, что запросы к системе останавливаются, то данные придут в консистентное состояние - следующим проходом регулярного процесса все устаревшие ссылки вычистятся и that's it. То есть имеет модель консистентности eventual consistency.

## Дальнейшая оптимизация

Чтобы снизить нагрузку, можно попробовать поставить перед бэкэндами инстанс с Redis, который будет использоваться для LRU-кэш для последних 1-10 миллионов ссылок. Если он падает - ничего страшного, ходим напрямую на бэкэнды как в прошлой схеме.

Базу можно шардировать для снижения нагрузки и в фоне реплицировать для улучшения доступности.

# Детали реализации

## Установка и настройка MongoDB

  1. Устанавливаем MongoDB. Инструкция здесь: https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/

  2. Создаем нужный для монги каталог:

     `sudo mkdir -r /data/db/`

  3. Запускаем сервер. Такие штуки видимо лучше в tmux-е запускать, разбив окно терминала на несколько частей, чтоб не заморачиваться и не плодить много терминалов.

     `sudo mongod`

  4. Приходим в консоль:

     `mongo`

  5. Создаем (или переключаемся) на базу сокращалки:

     `use url_shortener`

  6. Создаем коллекцию для соответствия slug-ов ссылкам:

     `db.createCollection("slug")`

  7. Создаем индексы по expiration_timestamp и по slug:

     `db.slug.createIndex( { expiration_timestamp: -1})`
     `db.slug.createIndex( { slug: -1 } )`

  8. Можно создать TTL-индекс по полю `expiration_timestamp`, но немного опасно. В том плане, что ссылка может истечь _согласно тому, что написано в базе_, но жить. И быть продленной следующей итерацией демона-продлевателя. А если согласно TTL-индексу она из базы уйдет, то мы ее потеряем и продлевать будет нечего.

## Установка драйвера MongoDB для C++

  1. Инструкция есть тут: http://mongocxx.org/mongocxx-v3/installation/
  
  2. Просто так пример не заведется. Это популярная проблема, ее можно решить, например, собирая и запуская так:
  
  `c++ --std=c++11 test.cpp $(pkg-config --cflags --libs libmongocxx) -Wl,-rpath,/usr/local/lib`
  `LD_LIBRARY_PATH=/usr/local/lib ./test`

## Настройки

В продакшене для обеспечения консистентности будем использовать write_concern = majority. Ссылка не может меняться после создания. Только TTL, который не виден пользователю и позже которого мы согласились иногда отдавать ссылку (но после истечения которого ничего не гарантируем). Поэтому кажется, что иметь read_concern = majority нам здесь необязательно - получили ссылку и хорошо.

Также ничего страшного не произойдет, если балансер сделает ретрай на таймаут или пятисотку при создании, поэтому можно настроить его на ретраи при 5xx и таймаутах.

Используем пул из коннекшенов >= числа тредов.

Консистентность подокументная у нас будет. На самом деле с ней вообще нет проблем для пользователя, потому что видимые ему поля не меняются. Консистентность всех ссылок что у нас есть в базе для пользователя очевидно не важна.
