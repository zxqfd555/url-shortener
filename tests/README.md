# Тестирование

Два типа тестирования: тестируем корректность (сервис ведет себя как надо) и тестируем нагрузочно (какой рейт сервис держит).

## Тесты корректности

Файл test_correctness_all.py. Чтоб запустить надо библиотека requests.

Проверяем, что продление ссылок работает. Для этого создаем ссылку с TTL равным 10 секунд и ходим по ней каждую секунду в течении 150 секунд. Удостоверяемся, что код ответа всегда 200. Строго говоря, конечно, 302. Но и браузер и Python requests видя 302 сразу редиректят на оригинальный урл и там уже вернут 200, сходив по нему.

Проверяем, что протухание ссылок работает. Для этого создаем ссылку с TTL равным 10 секунд, 20 секунд по ней не ходим, после чего делаем запрос. Убеждаемся, что там 404.

## Нагрузочные тесты

### Очень много переходов по ссылке

Ссылки на графики и генератор есть в load/get_one_long_link.

Это самый благоприятный кейс. Упремся в CPU. Без кэширования, а просто долблением монги получилось выжать 7000 RPS, причем с небольшим запасом по CPU.

Начал с 2K RPS. Как выжал семь:
  - Выключил весь логгинг.
  - Эксперименты с размером пула коннектов к монге.
  - Раз уж демон и access log живут в одном процессе, давайте вести лог не построчно, а храня map из slug-а во время последнего посещения.

### Очень много write-ов

Ссылки на графики есть в load/post_links.

Валится оно где-то на 1500 RPS, но ставить надо и того меньше. Проблема видимо в том, что мы DDoS-им базу на запись, выедаем все коннекты из пула и затем все сыпется.

На графике в CPU мы не упираемся. Проблема в другом: write-ы достаточно медленные, чтобы запросы на запись скапливались в очередь, когда их много. В итоге мы начинаем долго ждать. И кажется, что эту проблему можно было бы решить увеличением числа тредов в сервере, то есть в Crow в моем случае. Но нет: при большем количестве тредов начинает всплывать много context switch-ей, из-за чего работа тормозит еще больше.

Кажется, что можно было бы попробовать решать, выставив маленький таймаут на запросы на запись - мы бы тогда быстро отваливались и меньше вешали бы всю систему. Но Mongo CXX driver так не умеет: https://jira.mongodb.org/browse/CXX-1227 .  Увеличить размер пула коннектов тоже не особо помогает.

Но и ладно. И так мы знали, что долбить базу write-ами плохая идея. Вот еще раз экспериментально в этом убедились.

Резюмируя: на 300 RPS держится хорошо и стабильно. Кажется, что это не совсем real-life кейс. Все таки, в сокращалках сильно чаще по ссылке переходят, что постят новую. Иначе, для кого вообще их постят.

### Имитация "реального мира"

Ссылки на графики и генератор есть в load/real_world.

Нормально сымитировать, на самом деле, сложно.

Делаем 1% запросов на запись и 99% запросов на чтение. Читаем какое-то небольшое множество страниц, потому что кейс посещения за 5-10 секунд  __всех__ страниц коллекции - что-то странное. Берем id страниц из Пуассоновского распределения.

Еще одна проблема: нам в патронах надо знать заранее URL, который сгенерируется. А мы не можем, он рандомный. Чтобы это обойти, реализовал интерфейс генераторов slug-ов и использовал Sequential: https://github.com/zxqfd555/url-shortener/blob/master/src/lib/slug.h#L32

По итогу вышло неплохо. Создалось за три минуты около 10 тысяч страниц и посетилось довольно много - сотни тысяч. Все ломается на около 6К из-за CPU, но брал рейт с запасом: выбрал 4K. На нем несколько запусков работают уверенно хорошо: 10-20 ms в 98 перцентили в пике.

## Выводы по итогу нагрузочного тестирования

Хорошо, что сделали схему с демоном и продлением ссылок: второй тест показал, что без нее остановились бы на сотнях RPS - был бы write на каждый запрос. Схема с демоном позволила на реальном кейсе держать на одном инстансе рейт около 4K - заметно лучше.

В каких-то идеальных случаях можно держать до 7K, но не уверен, что это особо показательно. Надо исходить из планируемой нагрузки и возможно в дальнейших тестах уменьшать еще больше число write-ов, но все же не убирать их вовсе.
